# -*- coding: utf-8 -*-
"""DLimageClassification2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11BSssi7O0MaCtoRfL3lB951ba_zhOvH0

The first half "https://colab.research.google.com/drive/1u3YyBrXfPD5snHTVgRdld1g34FriQcDh?usp=sharing" in develop the base model has overfitted to the dataset.
On this colab enhance the dataset by resizing, rescale, flip, rotation, zooming on the dataset extented the quantity and can make model to train well better then previous model.
The accurary on the test data is 83 and loss is 36

To improve used callback on the model to store the model weight and bias to carry on the net epochs but it minimize the accurary and mazimize the loss.
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

PATH = '/content/drive/MyDrive/Colab Notebooks'
train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')
test_dir = os.path.join(PATH, 'test')
print(train_dir)
print(validation_dir)
print(test_dir)

train_dataset = image_dataset_from_directory(
 train_dir,
 image_size=(180, 180),
 batch_size=32)

validation_dataset = image_dataset_from_directory(
 validation_dir,
 image_size=(180, 180),
 batch_size=32)

test_dataset = image_dataset_from_directory(
 test_dir,
 image_size=(180, 180),
 batch_size=32)

IMG_SIZE = 180

resize_and_rescale = tf.keras.Sequential([
  layers.Resizing(IMG_SIZE, IMG_SIZE),
  layers.Rescaling(1./255)
])

get_label_name = ["7up","Amul","Balaji Wafers","Bingo","Britannia","Cheetos","Coco Cola","Dabur","Fanta","Haldiram's","Hershey's",
               "Kellogg's","Kissan","Kurkure","Lays","Maaza","Maggi","Mc Cain","Mother Dairy","Mtr","Orea","Paper boat",
               "Roof afza","Sunfeast","Vadilal"]

image, label = next(iter(train_dataset))
_ = plt.imshow(image[0].numpy().astype("uint8"))
_ = plt.title(get_label_name[label.numpy()[0]])

IMG_SIZE = 180

resize_and_rescale = tf.keras.Sequential([
  layers.Resizing(IMG_SIZE, IMG_SIZE),
  layers.Rescaling(1./255)
])
result = resize_and_rescale(image)
_ = plt.imshow(result[0])

print("Min and max pixel values:", result.numpy().min(), result.numpy().max())

data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.2),
 ]
)
plt.figure(figsize=(10, 10))
for images, _ in train_dataset.take(1):
    for i in range(9):
        augmented_images = data_augmentation(images)
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(augmented_images[0].numpy().astype("uint8"))
        plt.axis("off")

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(25))

model.summary()

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_dataset, epochs=10,
                    validation_data=validation_dataset)

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(test_dataset, verbose=2)

callbacks = [
 keras.callbacks.ModelCheckpoint(filepath=PATH+".keras",
 save_best_only=True,
 monitor="val_loss")
]
history = model.fit(train_dataset, epochs=10, validation_data=validation_dataset, callbacks=callbacks)

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(test_dataset, verbose=2)